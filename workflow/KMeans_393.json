{
  "name": "KMeans",
  "uuid": "09395cb5-a1a8-4407-be71-056bfa8455c3",
  "category": "KMeans",
  "parameters": "",
  "nodes": [
    {
      "id": "1",
      "name": "Read CSV",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>Refresh Schema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the refresh schema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "50px",
      "y": "325px",
      "hint": "Refresh the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "path",
          "value": "/root/Customer-Segmentation-Kutay/featured_data/part-00000-f400e075-6cab-4ef0-81e5-cb58a122374d-c000.csv",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"ID\",\"Year_Birth\",\"Education\",\"Marital_Status\",\"Income\",\"Kidhome\",\"Teenhome\",\"Dt_Customer\",\"Recency\",\"MntWines\",\"MntFruits\",\"MntMeatProducts\",\"MntFishProducts\",\"MntSweetProducts\",\"MntGoldProds\",\"NumDealsPurchases\",\"NumWebPurchases\",\"NumCatalogPurchases\",\"NumStorePurchases\",\"NumWebVisitsMonth\",\"AcceptedCmp3\",\"AcceptedCmp4\",\"AcceptedCmp5\",\"AcceptedCmp1\",\"AcceptedCmp2\",\"Complain\",\"Z_CostContact\",\"Z_Revenue\",\"Response\",\"Dt_Customer_date\",\"Age\",\"Total_Children\",\"Total_Spending\",\"Customer_Since\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"INTEGER\",\"STRING\",\"STRING\",\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "extraOptions",
          "value": "",
          "widget": "tab",
          "title": "ExtraOptions",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Extra Options Keys",
          "description": "Extra options available when reading CSV files. Examples :\n comment --> # (ignore comment lines in the file)\nignoreLeadingWhiteSpace --> false (Ignores leading white spaces in string columns)\nignoreTrailingWhiteSpace --> false (Ignores trailing white spaces in string columns).\nfilterPushdown --> true (Enables filter pushdown to optimize query performance.)\nsamplingRatio --> 1.0 (Specifies the ratio of rows to sample when inferring schema.)\nignoreCorruptFiles --> false (Skips files with corrupt data instead of failing.)\nignoreMissingFiles --> false (Skips missing files instead of failing.)\npathGlobFilter --> *.csv (Filters file paths based on a specified glob pattern.)\nrecursiveFileLookup --> false (Enables recursive file lookup in directories.)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "Extra Options"
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Extra Options Values",
          "description": "Config Values for the Corresponding keys",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "2",
      "name": "Cast To Single Type",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by casting the specified input columns to a new data type",
      "details": "This node creates a new DataFrame by casting the specified input columns to a new data type. All the selected columns would be cast to the specified data type.<br>\n<br>\nThe boolean field Replace Existing Columns indicates whether the existing column should be replaced or a new column should be created.<br>",
      "examples": "If incoming Dataframe has following columns with below specified datatype:<br>\n<br>\n<ul>\n<li> CUST_ID : Integer</li>\n<li> CUST_NAME : String</li>\n<li> DOB : Datetime</li>\n<li> AGE : Integer</li>\n</ul>\nand [DOB] and [AGE] are selected for casting to [STRING] datatype then outgoing Dataframe would have below datatypes:<br>\n<br>\n<ul>\n<li> CUST_ID : Integer</li>\n<li> CUST_NAME : String</li>\n<li> DOB : String</li>\n<li> AGE : String</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCastColumnType",
      "x": "225px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Income\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be cast to new data type",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColType",
          "value": "DOUBLE",
          "widget": "array",
          "title": "New Data Type",
          "description": "New data type for the selected columns (INTEGER, DOUBLE, STRING, LONG, SHORT)",
          "optionsArray": [
            "BOOLEAN",
            "BYTE",
            "DATE",
            "DECIMAL",
            "DOUBLE",
            "FLOAT",
            "INTEGER",
            "LONG",
            "SHORT",
            "STRING",
            "TIMESTAMP"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "replaceExistingCols",
          "value": "true",
          "widget": "array",
          "title": "Replace Existing Cols?",
          "description": "Whether to replace existing columns or create new ones?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "3",
      "name": "Select Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "400px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputCols",
          "value": "[\"Income\",\"Age\",\"Total_Spending\",\"NumWebPurchases\",\"NumStorePurchases\",\"NumWebVisitsMonth\",\"Recency\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "16",
      "name": "Vector Assembler",
      "description": "Merges multiple columns into a vector column.",
      "details": "",
      "examples": "<h2> h2: VectorAssembler Node Example</h2>\n<br>\nAssume that we have a DataFrame with the columns id, hour, mobile, userFeatures, and clicked:<br>\n<br>\n id | hour | mobile | userFeatures     | clicked<br>\n----|------|--------|------------------|---------<br>\n 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0<br>\n<br>\n If we set VectorAssembler's <b>input Selected columns</b> to hour, mobile, and userFeatures and <b>output column</b> to features, after transformation we should get the following DataFrame:<br>\n<br>\n id | hour | mobile | userFeatures     | clicked | features<br>\n----|------|--------|------------------|---------|-----------------------------<br>\n 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0     | [18.0, 1.0, 0.0, 10.0, 0.5]<br>",
      "type": "ml-transformer",
      "nodeClass": "fire.nodes.ml.NodeVectorAssembler",
      "x": "925px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Income\",\"Age\",\"Total_Spending\",\"NumWebPurchases\",\"NumStorePurchases\",\"NumWebVisitsMonth\",\"Recency\"]",
          "widget": "variables",
          "title": "Input Columns",
          "description": "Input column of type - all numeric, boolean and vector",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float",
            "vectorudt"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputCol",
          "value": "vector_feature",
          "widget": "textfield",
          "title": "Output Column",
          "description": "Output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "handleInvalid",
          "value": "error",
          "widget": "array",
          "title": "Handle Invalid",
          "description": "How to handle invalid data (NULL values). Options are 'skip' (filter out rows with invalid data), 'error' (throw an error), or 'keep' (return relevant number of NaN in the output).",
          "optionsArray": [
            "error",
            "skip",
            "keep"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "17",
      "name": "Standard Scaler",
      "description": "StandardScaler transforms a dataset of Vector rows, normalizing each feature to have unit standard deviation and/or zero mean.",
      "details": "<h2> Standard Scaler Node Details</h2>\n<br>\nThe Standard Scaler Node is used to normalize a dataset of Vector rows, by transforming each feature to have unit standard deviation and/or zero mean. It takes in the common parameters inputCol, outputCol, withMean, and withStd. The input column should be in the format of VectorUDT. The output column will also be in the format of VectorUDT.<br>\n<br>\nThe inputCol is the name of the feature column to be transformed. The outputCol is the name of the new column containing the transformed features. The withMean parameter, when set to true, centers the data with mean before scaling. The withStd parameter, when set to true, scales the data to unit standard deviation.<br>\n<br>\n<h4>Input Parameters</h4>\n<br>\nINPUT COLUMN : Select the required column for which Standard scaling has to be done .<br>\nOUTPUT COLUMN : The name of the output column after standard scaling.<br>\nWITH MEAN : Centers the data with mean before scaling.<br>\nWITH STANDARD DEVIATION : Scales the data to unit standard deviation.<br>",
      "examples": "<h2> Standard Scaler Node Example</h2>\n<br>\nConsider the below <b>Standard Scaler</b> output for the <b>features</b> column<br>\n<br>\nid features scaled_features<br>\n0 [1.0, 2.0, 3.0, 4.0] [-1.3416407864998738, -0.4472135954999579, 0.4472135954999579, 1.3416407864998738]<br>\n1 [-1.0, -2.0, -3.0, -4.0] [1.3416407864998738, 0.4472135954999579, -0.4472135954999579, -1.3416407864998738]<br>\nIn this example, the input column is features and the output column is scaled_features. The standard scaler scales the features to unit standard deviation by subtracting the mean of the features and then dividing by the standard deviation. The withMean parameter is set to true and withStd parameter is set to true. Here the mean of the features is (1.0+2.0+3.0+4.0)/4 = 2.5 and the standard deviation is sqrt((1^2+2^2+3^2+4^2)/4-2.5^2) = 1.2909944487358056.<br>",
      "type": "ml-estimator",
      "nodeClass": "fire.nodes.ml.NodeStandardScaler",
      "x": "1100px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "inputCol",
          "value": "vector_feature",
          "widget": "variable",
          "title": "Input Column",
          "description": "The input column name",
          "datatypes": [
            "vectorudt"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputCol",
          "value": "vector_features",
          "widget": "textfield",
          "title": "Output Column",
          "description": "The output column name",
          "datatypes": [
            "vectorudt"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "withMean",
          "value": "true",
          "widget": "array",
          "title": "With Mean",
          "description": "Centers the data with mean before scaling.",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "withStd",
          "value": "true",
          "widget": "array",
          "title": "With Standard Dev",
          "description": "Scales the data to unit standard deviation",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "18",
      "name": "Vector Assembler",
      "description": "Merges multiple columns into a vector column.",
      "details": "",
      "examples": "<h2> h2: VectorAssembler Node Example</h2>\n<br>\nAssume that we have a DataFrame with the columns id, hour, mobile, userFeatures, and clicked:<br>\n<br>\n id | hour | mobile | userFeatures     | clicked<br>\n----|------|--------|------------------|---------<br>\n 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0<br>\n<br>\n If we set VectorAssembler's <b>input Selected columns</b> to hour, mobile, and userFeatures and <b>output column</b> to features, after transformation we should get the following DataFrame:<br>\n<br>\n id | hour | mobile | userFeatures     | clicked | features<br>\n----|------|--------|------------------|---------|-----------------------------<br>\n 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0     | [18.0, 1.0, 0.0, 10.0, 0.5]<br>",
      "type": "ml-transformer",
      "nodeClass": "fire.nodes.ml.NodeVectorAssembler",
      "x": "1275px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "inputCols",
          "value": "[\"vector_features\"]",
          "widget": "variables",
          "title": "Input Columns",
          "description": "Input column of type - all numeric, boolean and vector",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float",
            "vectorudt"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputCol",
          "value": "new_vector_feature",
          "widget": "textfield",
          "title": "Output Column",
          "description": "Output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "handleInvalid",
          "value": "error",
          "widget": "array",
          "title": "Handle Invalid",
          "description": "How to handle invalid data (NULL values). Options are 'skip' (filter out rows with invalid data), 'error' (throw an error), or 'keep' (return relevant number of NaN in the output).",
          "optionsArray": [
            "error",
            "skip",
            "keep"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "19",
      "name": "Spark Predict",
      "description": "Predict node takes in a DataFrame and Model and makes predictions",
      "details": "Predict node takes in a DataFrame and Model and makes predictions on the data using the Model.<br>",
      "examples": "",
      "type": "ml-predict",
      "nodeClass": "fire.nodes.ml.NodePredict",
      "x": "1455.33px",
      "y": "473.333px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "20",
      "name": "K-Means",
      "description": "K-means clustering with support for k-means initialization proposed by Bahmani et al",
      "details": "k-means is one of the most commonly used clustering algorithms that clusters the data points into a predefined number of clusters. The MLlib implementation includes a parallelized variant of the k-means++ method called kmeans||.<br>\n<br>\nKMeans is implemented as an Estimator and generates a KMeansModel as the base model.<br>\n<br>\nMore details are available at Apache Spark ML docs page:<br>\n<br>\n<a href=\"https://spark.apache.org/docs/latest/ml-clustering.html#k-means\" target=\"_blank\">spark.apache.org/docs/latest/ml-clustering.html#k-means</a><br>",
      "examples": "Below example is available at : <a href=\"https://spark.apache.org/docs/latest/ml-clustering.html#k-means\" target=\"_blank\">spark.apache.org/docs/latest/ml-clustering.html#k-means</a><br>\n<br>\nimport org.apache.spark.ml.clustering.KMeans<br>\nimport org.apache.spark.ml.evaluation.ClusteringEvaluator<br>\n<br>\n// Loads data.<br>\nval dataset = spark.read.format(\"libsvm\").load(\"data/mllib/sample_kmeans_data.txt\")<br>\n<br>\n// Trains a k-means model.<br>\nval kmeans = new KMeans().setK(2).setSeed(1L)<br>\nval model = kmeans.fit(dataset)<br>\n<br>\n// Make predictions<br>\nval predictions = model.transform(dataset)<br>\n<br>\n// Evaluate clustering by computing Silhouette score<br>\nval evaluator = new ClusteringEvaluator()<br>\n<br>\nval silhouette = evaluator.evaluate(predictions)<br>\nprintln(s\"Silhouette with squared euclidean distance = $silhouette\")<br>\n<br>\n// Shows the result.<br>\nprintln(\"Cluster Centers: \")<br>\nmodel.clusterCenters.foreach(println)<br>",
      "type": "ml-estimator",
      "nodeClass": "fire.nodes.ml.NodeKMeans",
      "x": "1469.33px",
      "y": "329.333px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "modelIdentifier",
          "value": "",
          "widget": "textfield",
          "title": "Model Identifier",
          "description": "modelIdentifier starts with $loop & columns names separated with underscore. Example: $loop_columnName1_columnName2.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "featuresCol",
          "value": "new_vector_feature",
          "widget": "variable",
          "title": "Features Column",
          "description": "Features column of type vectorUDT for model fitting.",
          "datatypes": [
            "vectorudt"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "k",
          "value": "6",
          "widget": "textfield",
          "title": "K",
          "description": "The number of clusters to create.",
          "datatypes": [
            "integer"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "maxIter",
          "value": "300",
          "widget": "textfield",
          "title": "Max Iterations",
          "description": "The maximum number of iterations.",
          "datatypes": [
            "integer"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "predictionCol",
          "value": "",
          "widget": "textfield",
          "title": "Prediction Column",
          "description": "The prediction column created during model scoring.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "seed",
          "value": "1234",
          "widget": "textfield",
          "title": "Seed",
          "description": "Random Seed.",
          "datatypes": [
            "long"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "tol",
          "value": "1e-4",
          "widget": "textfield",
          "title": "Tolerence",
          "description": "The convergence tolerance for iterative algorithms.",
          "datatypes": [
            "double"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "initMode",
          "value": "k-means||",
          "widget": "array",
          "title": "initMode",
          "description": "The initialization algorithm mode.",
          "optionsArray": [
            "k-means||",
            "random"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "initSteps",
          "value": "10",
          "widget": "textfield",
          "title": "initSteps",
          "description": "The number of steps for the k-means initialization mode. It will be ignored when other initialization modes are chosen.",
          "datatypes": [
            "integer"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "distanceMeasure",
          "value": "euclidean",
          "widget": "array",
          "title": "distanceMeasure",
          "description": "Trait for shared param distanceMeasure",
          "optionsArray": [
            "euclidean",
            "cosine"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "weightCol",
          "value": "",
          "widget": "variable",
          "title": "Weight Column",
          "description": "Weight Column",
          "datatypes": [
            "double"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "22",
      "name": "SQL Transformer",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node runs the given SQL on the incoming DataFrame using Spark ML SQLTransformer",
      "details": "<h2> SQL Transformer Node Details</h2>\n<br>\nThe SQL Transformer Node implements the transformations which are defined by SQL statement. Currently,  supports SQL syntax like <br>\n<ul>\n<li> SELECT a, a + b AS ab FROM  tablename</li>\n<li> SELECT a, SQRT(b) AS bsqrt FROM tablename where a > 5</li>\n<li> SELECT a, b, SUM(c) AS csum FROM tablename GROUP BY a, b</li>\n</ul>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TEMP TABLE : Defaults to 'fire_temp_table'. A name provided for the underlying table of the input dataset.</li>\n<li> SQL : Enter the SQL statement for execution. The select clause specifies the fields, constants, and expressions to display in the output, and can be any select clause that Spark SQL supports.</li>\n</ul>",
      "examples": "<h2> SQL Transformer Node Example</h2>\n<br>\nAssume that we have the following DataFrame with columns id, v1 and v2:<br>\n<br>\nid  | v1  | v2<br>\n----|-----|-----<br>\n100 | 1.0 | 3.0<br>\n200 | 2.0 | 5.0<br>\n<br>\nThis is the output of the SQLTransformer with statement \"SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM fire_temp_table\" entered in the <b>SQL</b> box:<br>\n<br>\n id |  v1 |  v2 |  v3 |  v4<br>\n----|-----|-----|-----|-----<br>\n 0  | 1.0 | 3.0 | 4.0 | 3.0<br>\n 2  | 2.0 | 5.0 | 7.0 |10.0<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeSQLTransformer",
      "x": "575px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "sql",
          "value": "SELECT\n  CAST(Age AS DOUBLE)          AS Age,\n  CAST(Income AS DOUBLE)       AS Income,\n  CAST(Total_Spending AS DOUBLE) AS Total_Spending,\n  CAST(NumWebPurchases AS DOUBLE) AS NumWebPurchases,\n  CAST(NumStorePurchases AS DOUBLE) AS NumStorePurchases,\n  CAST(NumWebVisitsMonth AS DOUBLE) AS NumWebVisitsMonth,\n  CAST(Recency AS DOUBLE)      AS Recency\nFROM fire_temp_table",
          "widget": "textarea_large",
          "title": "SQL",
          "description": "SQL to be run",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"Age\",\"Income\",\"Total_Spending\",\"NumWebPurchases\",\"NumStorePurchases\",\"NumWebVisitsMonth\",\"Recency\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "23",
      "name": "Drop Rows With Null",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by dropping rows containing null values",
      "details": "This node creates a new DataFrame by dropping rows containing NULL values in any of the columns.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE05       |    MARK        |               |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE03       |    TONY        |    MARKETING  |    <br>\nE04       |    MARTIN      |    MARKETING  |    45<br>\n<br>\nIncoming Dataframe has NULL values for two rows. <br>\nUsing DropRowsWithNull node would result in below outgoing Dataframe created by dropping rows having NULL values in any of the columns:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE04       |    MARTIN      |    MARKETING  |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropRowsWithNull",
      "x": "750px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "25",
      "name": "Clustering Evaluator",
      "iconImage": "fa fa-qrcode",
      "description": "Evaluator for Clustering, which expects two input columns: features and prediction.",
      "details": "",
      "examples": "",
      "type": "ml-evaluator",
      "nodeClass": "fire.nodes.ml.NodeClusteringEvaluator",
      "x": "1285.96px",
      "y": "566.979px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "featuresCol",
          "value": "new_vector_feature",
          "widget": "variable",
          "title": "Features Column",
          "description": "Features column of type vectorUDT for model fitting.",
          "datatypes": [
            "vectorudt"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "predictionCol",
          "value": "prediction",
          "widget": "variable",
          "title": "Prediction Column",
          "description": "The prediction column.",
          "datatypes": [
            "double"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "27",
      "name": "Save CSV",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "Saves the DataFrame into the specified location in CSV Format",
      "details": "This node saves incoming Dataframe into the specified location in CSV format.<br>",
      "examples": "path-folder1/folder2/filename<br>\n<br>\nthe file will be saved under the file name at the path provided<br>\nif folder is not present it will be created and save the file<br>\nif the file already exists selection in save mode determines what happens to the file,append-adds the file data to it overwrite-replaces the file altogether<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.save.NodeSaveCSV",
      "x": "1644.65px",
      "y": "641.646px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "path",
          "value": "/root/Customer-Segmentation-Kutay/prediction",
          "widget": "textfield",
          "title": "Path",
          "description": "Path where to save the CSV files",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "saveMode",
          "value": "Append",
          "widget": "array",
          "title": "Save Mode",
          "description": "Whether to Append, Overwrite or Error if the path Exists",
          "optionsArray": [
            "Append",
            "Overwrite",
            "ErrorIfExists",
            "Ignore"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Should a Header Row be saved with each File?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "partitionColNames",
          "value": "[]",
          "widget": "variables",
          "title": "Partition Column Names",
          "description": "Partition Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "28",
      "name": "Select Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "1494px",
      "y": "831px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputCols",
          "value": "[\"prediction\",\"Age\",\"Income\",\"Total_Spending\",\"NumWebPurchases\",\"NumStorePurchases\",\"NumWebVisitsMonth\",\"Recency\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "1",
      "target": "2",
      "id": 1
    },
    {
      "source": "2",
      "target": "3",
      "id": 2
    },
    {
      "source": "17",
      "target": "18",
      "id": 3
    },
    {
      "source": "18",
      "target": "20",
      "id": 4
    },
    {
      "source": "20",
      "target": "19",
      "id": 5
    },
    {
      "source": "18",
      "target": "19",
      "id": 6
    },
    {
      "source": "16",
      "target": "17",
      "id": 7
    },
    {
      "source": "3",
      "target": "22",
      "id": 8
    },
    {
      "source": "22",
      "target": "23",
      "id": 9
    },
    {
      "source": "23",
      "target": "16",
      "id": 10
    },
    {
      "source": "19",
      "target": "25",
      "id": 11
    },
    {
      "source": "19",
      "target": "28",
      "id": 12
    },
    {
      "source": "28",
      "target": "27",
      "id": 13
    }
  ],
  "dataSetDetails": [],
  "engine": "scala"
}